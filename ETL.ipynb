{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtractTransformLoad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PlaneAccidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5008 entries, 0 to 5007\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   fecha                   5008 non-null   object\n",
      " 1   HORA declarada          5008 non-null   object\n",
      " 2   Ruta                    5008 non-null   object\n",
      " 3   OperadOR                5008 non-null   object\n",
      " 4   flight_no               5008 non-null   object\n",
      " 5   route                   5008 non-null   object\n",
      " 6   ac_type                 5008 non-null   object\n",
      " 7   registration            5008 non-null   object\n",
      " 8   cn_ln                   5008 non-null   object\n",
      " 9   all_aboard              5008 non-null   object\n",
      " 10  PASAJEROS A BORDO       5008 non-null   object\n",
      " 11  crew_aboard             5008 non-null   object\n",
      " 12  cantidad de fallecidos  5008 non-null   object\n",
      " 13  passenger_fatalities    5008 non-null   object\n",
      " 14  crew_fatalities         5008 non-null   object\n",
      " 15  ground                  5008 non-null   object\n",
      " 16  summary                 5008 non-null   object\n",
      "dtypes: object(17)\n",
      "memory usage: 665.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./PI03-Analytics-main/AccidentesAviones.csv')\n",
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df.info()\n",
    "#nulls in this dataset are determined by a '?' string char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's rename the columns to a standard\n",
    "dicc = {\n",
    "'fecha': 'date',                   \n",
    "'HORA declarada': 'declared_hour',        \n",
    "'Ruta': 'route',            \n",
    "'OperadOR': 'operator',              \n",
    "'flight_no': 'flight_n',             \n",
    "'route': 'route_type',                  \n",
    "'ac_type': 'ac_type',                \n",
    "'registration': 'registration',           \n",
    "'cn_ln': 'cn_ln',                  \n",
    "'all_aboard': 'aboard_total',            \n",
    "'PASAJEROS A BORDO': 'aboard_pass',      \n",
    "'crew_aboard': 'aboard_crew',            \n",
    "'cantidad de fallecidos': 'deceased_aboard_total',\n",
    "'passenger_fatalities': 'deceased_aboard_pass',  \n",
    "'crew_fatalities':'deceased_aboard_crew',        \n",
    "'ground': 'deceased_not_on_total',                 \n",
    "'summary': 'summary'  \n",
    "}\n",
    "df = df.rename(columns=dicc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                      0.000000\n",
       "declared_hour            30.031949\n",
       "route                     0.099840\n",
       "operator                  0.199681\n",
       "flight_n                 73.522364\n",
       "route_type               15.215655\n",
       "ac_type                   0.259585\n",
       "registration              5.431310\n",
       "cn_ln                    13.318690\n",
       "aboard_total              0.339457\n",
       "aboard_pass               4.412939\n",
       "aboard_crew               4.373003\n",
       "deceased_aboard_total     0.159744\n",
       "deceased_aboard_pass      4.692492\n",
       "deceased_aboard_crew      4.692492\n",
       "deceased_not_on_total     0.878594\n",
       "summary                   1.178115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see the % of nulls\n",
    "temp = df.replace('?',None)\n",
    "temp.isnull().sum()/len(temp) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can just drop the columns with way too many % of nulls, but because the flight_n is\n",
    "#our best bet at getting JOIN data with Top100Fatalities.csv we'll leave it\n",
    "df.drop('flight_n',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date: there seems to be nothing wrong with this column so I will just put it in date format\n",
    "df.date = df.date.apply(lambda x: datetime.strptime(x, '%B %d, %Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### Declared_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3289\n",
       "1    1504\n",
       "5     170\n",
       "7      37\n",
       "6       5\n",
       "3       3\n",
       "Name: declared_hour, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#declared_hour: this is in military hour so it needs to be 4 digits in length, so let's create a function that adapts to each type of length\n",
    "df.declared_hour.apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1718\n",
       "2       0630\n",
       "4       1830\n",
       "5       1030\n",
       "6       0100\n",
       "        ... \n",
       "5002    1705\n",
       "5003    1835\n",
       "5004    1800\n",
       "5005    0800\n",
       "5007    1500\n",
       "Name: declared_hour, Length: 3289, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.declared_hour.apply(lambda x: len(x)) == 4].declared_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2140    900\n",
       "3117    245\n",
       "3794    175\n",
       "Name: declared_hour, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.declared_hour.apply(lambda x: len(x)) == 3].declared_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132     10:00\n",
       "156     14:48\n",
       "160     11:30\n",
       "170     08:00\n",
       "171     10:45\n",
       "        ...  \n",
       "4380    02:30\n",
       "4385    11:23\n",
       "4531    05:30\n",
       "4742    0500Z\n",
       "5006    11:30\n",
       "Name: declared_hour, Length: 170, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.declared_hour.apply(lambda x: len(x)) == 5].declared_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158     c 9:15\n",
       "926     02:09Z\n",
       "1120    03:50Z\n",
       "1308    17:34Z\n",
       "1340    01:00Z\n",
       "Name: declared_hour, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.declared_hour.apply(lambda x: len(x)) == 6].declared_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.declared_hour.apply(lambda x: str(x)) #make sure everything is in string type\n",
    "\n",
    "def clean_str(x):\n",
    "    #I don't want null values to fill up the 00:00 time as it can change hour means/medians radically\n",
    "    if x == '?':\n",
    "        return x\n",
    "    # let's find every non digit in the string and replace it with nothing\n",
    "    x = re.sub(r'[^0-9]', '', x)\n",
    "    # strip extra spaces    \n",
    "    x = x.strip()\n",
    "    # there's an outlier that would not be an hour\n",
    "    if x == '175':\n",
    "        x = x.ljust(4, '0')\n",
    "    # fill up every <4 string with 0s\n",
    "    x = x.zfill(4)\n",
    "    return x\n",
    "# apply it\n",
    "df.declared_hour = df.declared_hour.apply(clean_str)\n",
    "\n",
    "# now make it into the standard hh:mm format\n",
    "def timeConvert(x):\n",
    "    if x == '?':\n",
    "        return x\n",
    "    x = x[ :2] + ':' + x[2: ]\n",
    "    pd.to_datetime(x, format='%H:%M')\n",
    "    return x\n",
    "\n",
    "df.declared_hour = df.declared_hour.apply(timeConvert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360     ?\n",
       "465     ?\n",
       "646     ?\n",
       "999     ?\n",
       "2895    ?\n",
       "Name: route, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there seem to be only 5 nulls here, so I can just leave them here\n",
    "df[df.route == '?'].route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### operator, route_type, ac_type, aboard_x, deceased_x, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operator                  0.199681\n",
       "route_type               15.215655\n",
       "ac_type                   0.259585\n",
       "registration              5.431310\n",
       "cn_ln                    13.318690\n",
       "aboard_total              0.339457\n",
       "aboard_pass               4.412939\n",
       "aboard_crew               4.373003\n",
       "deceased_aboard_total     0.159744\n",
       "deceased_aboard_pass      4.692492\n",
       "deceased_aboard_crew      4.692492\n",
       "deceased_not_on_total     0.878594\n",
       "summary                   1.178115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#they have a really low number of nulls (the outlier here is route_type, but it still isn't enough to justify dropping it)\n",
    "temp = df.replace('?',None)\n",
    "temp = temp.iloc[:,3:]\n",
    "temp.isnull().sum()/len(temp) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I change null value from ? to real None type so each feature can have the correct data type in MySQL\n",
    "df = df.replace('?',None)\n",
    "df.to_csv('./datasets/PlaneAccidents.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top100Fatalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_html('http://www.planecrashinfo.com/worst100.htm',header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index column\n",
    "df2.drop(['Unnamed: 0','Photo'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "dicc = {\n",
    "'Fatal': 'fatalities',                   \n",
    "'Date': 'date',        \n",
    "'Location': 'location',            \n",
    "'Carrier': 'carrier',              \n",
    "'Flight': 'flight',             \n",
    "'Type': 'type'                  \n",
    "}\n",
    "df2 = df2.rename(columns=dicc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the 'Fatal'[0] as it had annotations from the web page\n",
    "df2.fatalities[0] = 2907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities    0.00000\n",
       "date          0.00000\n",
       "location      0.00000\n",
       "carrier       0.00000\n",
       "flight        9.90099\n",
       "type          0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null values here are '-'\n",
    "temp = df2.replace('-',None)\n",
    "temp.isnull().sum()/len(temp) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get date in the same standard as PlaneAccidents.csv\n",
    "df2.date = df2.date.apply(lambda x: datetime.strptime(x, '%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before saving it we need to change null values into real None types so we can get the whole column in the correct data type in MySQL\n",
    "df2 = df2.replace('-',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is super clean and relevant to everything I'm gonna talk about so there's nothing else to do.\n",
    "df2.to_csv('./datasets/Top100Fatalities.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ac6b331241b7728a7834e385d83880cebc71c0087974d14f8814364ef908e6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
